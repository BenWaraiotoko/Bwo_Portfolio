---
title: Fundamentals Hub - Your Complete Learning Map
date: 2026-01-22
publish: true
description: Index and navigation for all data engineering fundamentals, organized by domain and learning level.
tags:
  - fundamentals
  - index
  - learning-map
category: second-brain
---
# Fundamentals Hub ğŸ“š

Your complete guide to data engineering fundamentals. Use this page to navigate by **domain** or **learning level**.

---

## ğŸš€ Quick Start (First 2 Weeks)

**If you have 2 weeks before bootcamp:**

1. **Day 1-3:** Read [[0-Data-Engineering-Fundamentals]]
2. **Day 4-7:** Learn [[Docker-Fundamentals]] (3h)
3. **Day 8-14:** Learn [[Apache-Airflow]] (5h)

**Result:** Understand architecture, know tools, ready for Week 1

---

## ğŸ“– By Domain

### **Concepts & Theory**

| Document                            | Focus                     | Time | Level       |
| ----------------------------------- | ------------------------- | ---- | ----------- |
| [[0-Data-Engineering-Fundamentals]] | What is data engineering? | 1.5h | ğŸŸ¢ Beginner |
| [[TOOLS-Learning-Roadmap]]          | How tools fit together    | 0.5h | ğŸŸ¢ Beginner |

### **Containerization & DevOps**

| Document | Focus | Time | Level |
|----------|-------|------|-------|
| [[Docker-Fundamentals]] | Images, containers, volumes | 3h | ğŸŸ¢ Beginner |
| [[Docker-Compose]] | Multi-container orchestration | 4h | ğŸŸ¡ Intermediate |
| [[Git-GitHub]] | Version control & collaboration | 2h | ğŸŸ¢ Beginner |
| [[git-cheatsheet]] | Quick command reference | 0.5h | ğŸŸ¢ Beginner |

### **Orchestration & Scheduling**

| Document | Focus | Time | Level |
|----------|-------|------|-------|
| [[Apache-Airflow]] | DAGs, operators, scheduling | 5h | ğŸŸ¡ Intermediate |

### **Transformation & Testing**

| Document | Focus | Time | Level |
|----------|-------|------|-------|
| [[dbt-Data-Build-Tool]] | SQL models, tests, documentation | 5h | ğŸŸ¡ Intermediate |

### **Distributed Computing**

| Document | Focus | Time | Level |
|----------|-------|------|-------|
| [[PySpark-Fundamentals]] | RDDs, DataFrames, SQL | 4h | ğŸŸ¡ Intermediate |

### **Cloud Platforms**

| Document | Focus | Time | Level |
|----------|-------|------|-------|
| [[Cloud-Data-Warehouses]] | Snowflake, BigQuery, Redshift | 4h | ğŸŸ¡ Intermediate |

---

## ğŸ“Š By Learning Level

### ğŸŸ¢ Beginner (Start Here)

Foundational concepts, local development:

1. [[0-Data-Engineering-Fundamentals]] â€” Understand the field
2. [[Docker-Fundamentals]] â€” Package your code
3. [[Git-GitHub]] â€” Version control like a professional
4. [[TOOLS-Learning-Roadmap]] â€” See the big picture

**After:** You can run a simple pipeline locally

### ğŸŸ¡ Intermediate (Week 2-3)

Industry-standard tools, production patterns:

1. [[Docker-Compose]] â€” Multi-service stacks
2. [[Apache-Airflow]] â€” Automated workflows
3. [[dbt-Data-Build-Tool]] â€” Data transformations
4. [[git-cheatsheet]] â€” Workflow automation

**After:** You can build production-ready pipelines

### ğŸ”´ Advanced (Week 4-6)

Scaling and cloud platforms:

1. [[PySpark-Fundamentals]] â€” Big data processing
2. [[Cloud-Data-Warehouses]] â€” Managed warehouses
3. Integrate all tools (Docker + Airflow + dbt + Spark + Cloud)

**After:** You're job-ready

---

## ğŸ—ºï¸ Learning Paths by Goal

### Goal: "Understand data engineering (1.5h)"

```
Data-Engineering-Fundamentals-Updated (1.5h)
â””â”€ Concepts only, no hands-on
```

### Goal: "Build a simple pipeline locally (12h)"

```
1. Data-Engineering-Fundamentals-Updated (1.5h) â€” Understand
2. Docker-Fundamentals (3h) â€” Container basics
3. Apache-Airflow (5h) â€” Orchestration
4. Git-GitHub (2h) â€” Version control
â””â”€ Build first project: Airflow + Docker + Git
```

### Goal: "Be bootcamp-ready (19h)"

```
1. TIER 1 Fundamentals (9h)
   - Docker-Fundamentals
   - Docker-Compose
   - Git-GitHub
2. TIER 2 Tools (10h)
   - Apache-Airflow
   - dbt-Data-Build-Tool
3. Build integrated ETL project
â””â”€ Ready for Le Wagon Week 1
```

### Goal: "Be job-ready (27h)"

```
1. TIER 1 (9h) â€” Containerization
2. TIER 2 (10h) â€” Orchestration & transformation
3. TIER 3 (8h)
   - PySpark-Fundamentals
   - Cloud-Data-Warehouses
4. Build capstone project
5. Publish portfolio
â””â”€ Ready for junior DE roles
```

---

## ğŸ”„ Recommended Daily Workflow

### Phase 1: Fundamentals (Days 1-3)

```
9:00 - 10:00  Read: Data-Engineering-Fundamentals-Updated
10:00 - 11:00 Watch: Docker intro video (find on YouTube)
11:00 - 12:00 Notes & summarize concepts
12:00 - 13:00 Lunch break
13:00 - 14:00 Practical: Install Docker, run first container
14:00 - 15:00 Review & questions
```

### Phase 2: Core Tools (Days 4-10)

```
9:00 - 9:30  Review previous day
9:30 - 10:30 Read new TOOL page
10:30 - 12:00 Follow along with examples
12:00 - 13:00 Lunch break
13:00 - 14:30 Write your own code (DAG, model, Dockerfile)
14:30 - 15:00 Test & fix errors
15:00 - 15:30 Commit to Git
```

### Phase 3: Integration (Days 11-14)

```
9:00 - 12:00 Project work (combine 2-3 tools)
12:00 - 13:00 Lunch break
13:00 - 15:00 Continue project + debugging
15:00 - 15:30 Git push + documentation
```

---

## ğŸ¯ Consolidation Milestones

### After Fundamentals + Docker (Day 3)
- [ ] Explain what data engineering is
- [ ] Run a Docker container locally
- [ ] Commit code to Git

### After Airflow (Day 7)
- [ ] Write an Airflow DAG with 3 tasks
- [ ] Schedule it to run
- [ ] View logs in Airflow UI

### After dbt (Day 10)
- [ ] Write a dbt model with tests
- [ ] Run `dbt test` successfully
- [ ] Generate documentation

### After Integration (Day 14)
- [ ] Build ETL: Airflow â†’ dbt â†’ Cloud warehouse
- [ ] All code in Git with clean history
- [ ] Project README ready

---

## ğŸš¨ Common Mistakes

| Mistake                       | How to Avoid                  | Covered In                          |
| ----------------------------- | ----------------------------- | ----------------------------------- |
| Starting tools without theory | Read fundamentals first       | [[0-Data-Engineering-Fundamentals]] |
| Skipping testing              | Write tests as you code       | [[dbt-Data-Build-Tool]]             |
| Not using version control     | Commit every day              | [[Git-GitHub]]                      |
| Hardcoding credentials        | Always use .env               | [[Docker-Fundamentals]]             |
| Building on local only        | Use Docker from day 1         | [[Docker-Fundamentals]]             |
| Complex pipelines from start  | Start simple, scale gradually | [[Apache-Airflow]]                  |

---

## ğŸ“š Integration Map

How all documents connect:

```
Data-Engineering-Fundamentals-Updated
    â†“
[Concepts & why things matter]
    â†“
    â”œâ”€â†’ Docker-Fundamentals
    â”‚       â†“
    â”‚   Package code consistently
    â”‚       â†“
    â”œâ”€â†’ Docker-Compose
    â”‚       â†“
    â”‚   Run multi-service locally
    â”‚
    â”œâ”€â†’ Git-GitHub
    â”‚       â†“
    â”‚   Version control everything
    â”‚
    â”œâ”€â†’ Apache-Airflow
    â”‚       â†“
    â”‚   Schedule automated workflows
    â”‚
    â”œâ”€â†’ dbt-Data-Build-Tool
    â”‚       â†“
    â”‚   Transform with tests
    â”‚
    â”œâ”€â†’ PySpark-Fundamentals
    â”‚       â†“
    â”‚   Scale to big data
    â”‚
    â””â”€â†’ Cloud-Data-Warehouses
            â†“
        Deploy to production
            â†“
        TOOLS-Learning-Roadmap-Updated
        [See how it all fits]
```

---

## ğŸ“ Before You Start

**Prerequisites:**
- [ ] Python basics (functions, loops, dicts) â€” from 1_PYTHON
- [ ] SQL basics (SELECT, WHERE, JOIN) â€” from 2_SQL
- [ ] Command line comfort (cd, ls, mkdir)
- [ ] Text editor (VS Code recommended)

**Install:**
```bash
python --version    # 3.8+
docker --version    # Latest
git --version       # Latest
```

---

## ğŸ†˜ Stuck? Here's How to Debug

1. **Conceptual confusion?**  
   â†’ Re-read that section of [[0-Data-Engineering-Fundamentals]]

2. **Docker error?**  
   â†’ Check "Tips & Gotchas" in [[Docker-Fundamentals]]

3. **DAG won't run?**  
   â†’ See [[Apache-Airflow]] "Debugging" section

4. **dbt test failed?**  
   â†’ Check [[dbt-Data-Build-Tool]] error handling

5. **Merge conflict?**  
   â†’ See [[Git-GitHub]] "Resolving Conflicts"

6. **Git lost?**  
   â†’ Use [[git-cheatsheet]] emergency commands

---

## ğŸ“ Study Buddies & Resources

**Official Documentation:**
- Docker: https://docs.docker.com
- Airflow: https://airflow.apache.org/docs
- dbt: https://docs.getdbt.com
- Spark: https://spark.apache.org/docs/latest
- Git: https://git-scm.com/doc

**YouTube Channels:**
- Seattle Data Guy (data engineering tutorials)
- Coder2J (practical examples)
- Alex The Analyst (career guidance)

**Communities:**
- r/dataengineering
- Data Engineering Wiki
- Local tech meetups

---

## âœ… You're Ready When...

- [ ] You can explain data engineering to a friend
- [ ] You can build a Docker image from a Dockerfile
- [ ] You can write and run an Airflow DAG
- [ ] You can write dbt models with tests
- [ ] You understand ETL vs ELT
- [ ] You can commit code to Git properly
- [ ] You can troubleshoot basic pipeline issues
- [ ] You've built a complete end-to-end project

**Check all boxes?** â†’ You're ready for Le Wagon! ğŸš€

---

## ğŸ—“ï¸ Timeline (Before Oct 31, 2026)

| Timeline | What | Status |
|----------|------|--------|
| Week 1-2 (by Jan 31) | Read fundamentals + TIER 1 | â³ In progress |
| Week 3-4 (by Feb 21) | Complete TIER 2 | ğŸ“‹ Planned |
| Week 5-6 (by Mar 7) | Start TIER 3 | ğŸ“‹ Planned |
| July-Sep | Deep dives + portfolio | ğŸ“‹ Planned |
| Oct 1-30 | Final prep + mock projects | ğŸ“‹ Planned |
| Oct 31 | Le Wagon Bootcamp Begins ğŸ‰ | ğŸš€ Goal |

---

## ğŸ† Your Success Metrics

By completion:

âœ… Understand modern data engineering principles  
âœ… Can containerize applications with Docker  
âœ… Can orchestrate workflows with Airflow  
âœ… Can transform data with dbt + testing  
âœ… Can process large data with Spark  
âœ… Can deploy to cloud warehouses  
âœ… Can collaborate professionally with Git  
âœ… Have portfolio project you're proud of  
âœ… Confident for Le Wagon bootcamp  
âœ… Job-ready as junior data engineer  

---

## ğŸš€ Next Steps

1. **Today:** Read [[0-Data-Engineering-Fundamentals]]
2. **Tomorrow:** Start [[Docker-Fundamentals]]
3. **This week:** Build first Docker container
4. **Next week:** Learn Airflow
5. **By Jan 31:** Complete TIER 1 + TIER 2

---

**Last Updated:** Jan 22, 2026  
**Designed for:** Benjamin (bootcamp start: Oct 31, 2026)  
**Total investment:** 27-35 hours  
**Expected outcome:** Job-ready junior data engineer
